{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac272ca8-08dd-4670-b1de-24c09506bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_218016/3339806485.py:24: ProplotWarning: rc setting 'linewidth' was renamed to 'meta.width' in version 0.8.\n",
      "  plot.rc.update({'figure.facecolor':'w','axes.labelweight':'ultralight',\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob,os,sys\n",
    "from tqdm.auto import tqdm\n",
    "import proplot as plot\n",
    "import json,pickle\n",
    "import dask.array as da\n",
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "sys.path.insert(1, '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/scikit/')\n",
    "from tools import derive_var,read_and_proc,preproc_noensemble\n",
    "from tools.mlr import mlr,proc_mlrfcst,maria_IO,ffs\n",
    "from tools.preprocess import do_eof,preproc_maria,preproc_haiyan\n",
    "sys.path.insert(2, '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/testML/')\n",
    "import feature_select\n",
    "from dask.distributed import Client\n",
    "client = Client(processes=True, threads_per_worker=1,n_workers=2)\n",
    "%matplotlib inline\n",
    "plot.rc.update({'figure.facecolor':'w','axes.labelweight':'ultralight',\n",
    "                'tick.labelweight':'ultralight','gridminor.linestyle':'--','title.weight':'normal','linewidth':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ee8141-d645-4e52-bf0f-110fb805c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diff(arrayin=None,delta=None,axis=None,LT=1):\n",
    "    result = []\n",
    "    if axis==0:\n",
    "        for i in range(0,arrayin.shape[axis]-LT):\n",
    "            temp = (arrayin[i+LT,:]-arrayin[i,:])/(LT*delta)\n",
    "            result.append(temp)\n",
    "        return np.asarray(result)\n",
    "    \n",
    "from sklearn.metrics import r2_score    \n",
    "class retrieve_cartesian:\n",
    "    def __init__(self,PCA_dict=None,Af_dict=None,numcomp=[11,11,15],LT=None,forecastPC=None,target='all',suffix=None):\n",
    "        self.PCA_dict=PCA_dict\n",
    "        self.numcomp=numcomp\n",
    "        self.forecastPC = forecastPC\n",
    "        self.LT = LT\n",
    "        self.target=target\n",
    "        self.suffix=suffix\n",
    "        \n",
    "    def get_time_diff_terms(self,inputvar=None,LT=None,wantvar=None):\n",
    "        def _get_time_diff(array=None,timedelta=60*60,LT=None):\n",
    "            store = []\n",
    "            for exp in array:\n",
    "                a = forward_diff(exp,timedelta,0,LT)\n",
    "                if a.shape[0]>0:\n",
    "                    azero = np.zeros((LT,exp.shape[-1]))\n",
    "                    store.append(np.asarray(a))\n",
    "                    #store.append(np.concatenate((a,azero),axis=0))\n",
    "                else:\n",
    "                    continue\n",
    "                    #store.append(np.zeros((exp.shape[0],exp.shape[-1])))\n",
    "            return store\n",
    "        \n",
    "        storedict = {}\n",
    "        for wantvarZ,wantvarN in enumerate(wantvar):\n",
    "            storedict[wantvarN] = _get_time_diff(array=inputvar[wantvarZ],LT=LT)\n",
    "        return storedict\n",
    "    \n",
    "    def _pop_valid_test(self,examplist=None,validindex=None,testindex=None):\n",
    "        [examplist.pop(i) for i in validindex]\n",
    "        [examplist.pop(i) for i in testindex]\n",
    "        return None\n",
    "        \n",
    "    def windrates_real(self,uvwheatpath=None,LT=None,category='train',validindex=[1,6],testindex=[2,12]):\n",
    "        u = [read_and_proc.depickle(path+uvwheatpath+'mem'+str(lime)+self.suffix)['u'] for lime in (range(1,21))].copy()\n",
    "        v = [read_and_proc.depickle(path+uvwheatpath+'mem'+str(lime)+self.suffix)['v'] for lime in (range(1,21))].copy()\n",
    "        w = [read_and_proc.depickle(path+uvwheatpath+'mem'+str(lime)+self.suffix)['w'] for lime in (range(1,21))].copy()\n",
    "        theta = [read_and_proc.depickle(path+uvwheatpath+'mem'+str(lime)+self.suffix)['theta'] for lime in (range(1,21))].copy()\n",
    "        \n",
    "        if category=='train':\n",
    "            popindex = validindex+testindex\n",
    "            ut = [u[i] for i in range(len(u)) if i not in popindex]\n",
    "            vt = [v[i] for i in range(len(v)) if i not in popindex]\n",
    "            wt = [w[i] for i in range(len(w)) if i not in popindex]\n",
    "            thetat = [theta[i] for i in range(len(theta)) if i not in popindex]\n",
    "            #self._pop_valid_test(u,validindex,testindex)\n",
    "            #self._pop_valid_test(v,validindex,testindex)\n",
    "            #self._pop_valid_test(w,validindex,testindex)\n",
    "            #self._pop_valid_test(theta,validindex,testindex)\n",
    "            assert len(ut)==16, 'wrong train-valid-test separation!'\n",
    "            dtermsT = self.get_time_diff_terms(inputvar=[ut,vt,wt,thetat],LT=LT,wantvar=['u','v','w','theta'])\n",
    "        elif category=='valid':\n",
    "            uv = [u[index] for index in validindex]\n",
    "            vv = [v[index] for index in validindex]\n",
    "            wv = [w[index] for index in validindex]\n",
    "            thetav = [theta[index] for index in validindex]\n",
    "            del u,v,w,theta\n",
    "            gc.collect()\n",
    "            dtermsT = self.get_time_diff_terms(inputvar=[uv,vv,wv,thetav],LT=LT,wantvar=['u','v','w','theta'])\n",
    "        elif category=='test':\n",
    "            ut = [u[index] for index in testindex]\n",
    "            vt = [v[index] for index in testindex]\n",
    "            wt = [w[index] for index in testindex]\n",
    "            thetat = [theta[index] for index in testindex]            \n",
    "            del u,v,w,theta\n",
    "            gc.collect()\n",
    "            dtermsT = self.get_time_diff_terms(inputvar=[ut,vt,wt,thetat],LT=LT,wantvar=['u','v','w','theta'])            \n",
    "        \n",
    "        dudt = np.concatenate([testx for testx in dtermsT['u']],axis=0)\n",
    "        dvdt = np.concatenate([testx for testx in dtermsT['v']],axis=0)\n",
    "        dwdt = np.concatenate([testx for testx in dtermsT['w']],axis=0)\n",
    "        dthdt = np.concatenate([testx for testx in dtermsT['theta']],axis=0)\n",
    "        del dtermsT\n",
    "        gc.collect()\n",
    "        return dudt,dvdt,dwdt,dthdt\n",
    "    \n",
    "    def output_reshapeRECON(self,forecast_eig=None):\n",
    "        if (self.target=='surface') or (self.target=='alluv'):\n",
    "            testrec_dudt = np.dot(forecast_eig[:,0:self.numcomp[0]],(self.PCA_dict['u'].components_[0:self.numcomp[0]]))#.reshape((91,39,360,167))\n",
    "            testrec_dvdt = np.dot(forecast_eig[:,self.numcomp[0]:self.numcomp[0]+self.numcomp[1]],(self.PCA_dict['v'].components_[0:self.numcomp[1]]))#.reshape((91,39,360,167))\n",
    "            return testrec_dudt,testrec_dvdt\n",
    "        else:\n",
    "            testrec_dudt = np.dot(forecast_eig[:,0:self.numcomp[0]],(self.PCA_dict['u'].components_[0:self.numcomp[0]]))#.reshape((91,39,360,167))\n",
    "            testrec_dvdt = np.dot(forecast_eig[:,self.numcomp[0]:self.numcomp[0]+self.numcomp[1]],(self.PCA_dict['v'].components_[0:self.numcomp[1]]))#.reshape((91,39,360,167))\n",
    "            testrec_dwdt = np.dot(forecast_eig[:,self.numcomp[0]+self.numcomp[1]:self.numcomp[0]+self.numcomp[1]+self.numcomp[2]],(self.PCA_dict['w'].components_[0:self.numcomp[2]]))#.reshape((39,360,167))\n",
    "            testrec_dthdt = np.dot(forecast_eig[:,self.numcomp[0]+self.numcomp[1]+self.numcomp[2]:],(self.PCA_dict['theta'].components_[0:self.numcomp[3]]))#.reshape((39,360,167))\n",
    "            return testrec_dudt,testrec_dvdt,testrec_dwdt,testrec_dthdt\n",
    "        \n",
    "    def conversion_predictPC(self,yforecast=None,mshpe=[39,360,167]):\n",
    "        if self.target=='surface':\n",
    "            t1,t2 = self.output_reshapeRECON(forecast_eig=yforecast)\n",
    "            return (t1.reshape(t1.shape[0],mshpe[0],mshpe[1],mshpe[2])[:,0,:,:]).reshape(t1.shape[0],mshpe[1]*mshpe[2]),(t2.reshape(t2.shape[0],mshpe[0],mshpe[1],mshpe[2])[:,0,:,:]).reshape(t2.shape[0],mshpe[1]*mshpe[2])\n",
    "        elif self.target=='alluv':\n",
    "            t1,t2 = self.output_reshapeRECON(forecast_eig=yforecast)\n",
    "            return t1,t2\n",
    "        elif self.target=='all': \n",
    "            t1,t2,t3,t4 = self.output_reshapeRECON(forecast_eig=yforecast)\n",
    "            return t1,t2,t3,t4\n",
    "        \n",
    "    def output_r2(self,FFWmodels=None,reducedX=None,realU=None,realV=None,realW=None,realTH=None,case='Haiyan',numoutput=5):\n",
    "        yf = [models.predict(Xns) for (models,Xns) in zip(FFWmodels[:],reducedX[:])]\n",
    "        mlr_r2 = []\n",
    "        for i in (range(numoutput)):#len(yf))):\n",
    "            if case=='Maria':\n",
    "                temp1,temp2 = self.conversion_predictPC(yforecast=yf[i],mshpe=[39,360,167])\n",
    "                mlr_r2.append(r2_score(np.concatenate((realU,realV),axis=0),np.concatenate((temp1,temp2),axis=0)))\n",
    "            elif case=='Haiyan':\n",
    "                try:\n",
    "                    temp1,temp2 = self.conversion_predictPC(yforecast=yf[i],mshpe=[10,360,208])\n",
    "                    a = r2_score(np.concatenate((realU,realV),axis=0),np.concatenate((temp1,temp2),axis=0))\n",
    "                    print(a)\n",
    "                    mlr_r2.append(a)\n",
    "                except:\n",
    "                    temp1,temp2,temp3,temp4 = self.conversion_predictPC(yforecast=yf[i],mshpe=[10,360,208])\n",
    "                    a = r2_score(np.concatenate((realU,realV,realW,realTH),axis=0),np.concatenate((temp1,temp2,temp3,temp4),axis=0))\n",
    "                    #print(a)\n",
    "                    mlr_r2.append(a)\n",
    "            del temp1,temp2\n",
    "            gc.collect()\n",
    "        return mlr_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15982160-7dee-4ee4-b7fd-8b1798286262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectorMixin\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import BaseEstimator, MetaEstimatorMixin, clone\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "    \n",
    "class forwardfeatureadder(BaseEstimator,SelectorMixin,MetaEstimatorMixin):\n",
    "    \"\"\"Transformer to add feature at a sequential order\n",
    "    Parameters:\n",
    "    estimator: Regression model\n",
    "    n_features_to_select: number of features to add to the model\n",
    "    cv: how many folds would we want during cross-validation\n",
    "    n_jobs: Parallelization\n",
    "    startfeatures: Features we would like to include in the model without cross-validation [we do this to accentuate the role of heating]\n",
    "    \n",
    "    Output:\n",
    "    self instance\n",
    "    \"\"\"\n",
    "    def __init__(self,estimator,n_features_to_select=None,cv=5,n_jobs=None,startfeatures=None,PCAdict=None,Afdict=None,numcomp=None,LT=None,optigoal='all',realWRF=None,mshpe=[10,360,208],r2_based='Yes',\\\n",
    "                Xtrain=None,ytrain=None):\n",
    "        self.estimator = estimator\n",
    "        self.n_features_to_select = n_features_to_select\n",
    "        self.cv = cv\n",
    "        self.n_jobs = n_jobs\n",
    "        self.startfeatures = startfeatures\n",
    "        self.PCAdict = PCAdict\n",
    "        self.Afdict = Afdict\n",
    "        self.numcomp = numcomp\n",
    "        self.LT = LT\n",
    "        self.optigoal = optigoal\n",
    "        self.realWRF = realWRF\n",
    "        self.mshpe = mshpe\n",
    "        self.r2_based=r2_based\n",
    "        self.Xtrain=Xtrain\n",
    "        self.ytrain=ytrain\n",
    "    \n",
    "    def get_real_winds(self):\n",
    "        temp1,temp2,temp3,temp4 = proc_mlrfcst.retrieve_cartesian(PCA_dict=self.PCAdict,Af_dict=self.Afdict,numcomp=self.numcomp,LT=self.LT,\n",
    "                            forecastPC=None).windrates_real(LT=self.LT)\n",
    "        return temp1,temp2,temp3,temp4\n",
    "    \n",
    "    def output_reshapeRECON(self,forecast_eig=None):\n",
    "        if (self.optigoal=='surface') or (self.optigoal=='alluv'):\n",
    "            testrec_dudt = np.dot(forecast_eig[:,0:self.numcomp[0]],(self.PCAdict['u'].components_[0:self.numcomp[0]]))#.reshape((91,39,360,167))\n",
    "            testrec_dvdt = np.dot(forecast_eig[:,self.numcomp[0]:self.numcomp[0]+self.numcomp[1]],(self.PCAdict['v'].components_[0:self.numcomp[1]]))#.reshape((91,39,360,167))\n",
    "            return testrec_dudt,testrec_dvdt\n",
    "        else:\n",
    "            testrec_dudt = np.dot(forecast_eig[:,0:self.numcomp[0]],(self.PCAdict['u'].components_[0:self.numcomp[0]]))#.reshape((91,39,360,167))\n",
    "            testrec_dvdt = np.dot(forecast_eig[:,self.numcomp[0]:self.numcomp[0]+self.numcomp[1]],(self.PCAdict['v'].components_[0:self.numcomp[1]]))#.reshape((91,39,360,167))\n",
    "            testrec_dwdt = np.dot(forecast_eig[:,self.numcomp[0]+self.numcomp[1]:self.numcomp[0]+self.numcomp[1]+self.numcomp[2]],(self.PCAdict['w'].components_[0:self.numcomp[2]]))#.reshape((39,360,167))\n",
    "            testrec_dthdt = np.dot(forecast_eig[:,self.numcomp[0]+self.numcomp[1]+self.numcomp[2]:],(self.PCAdict['theta'].components_[0:self.numcomp[3]]))#.reshape((39,360,167))\n",
    "            return testrec_dudt,testrec_dvdt,testrec_dwdt,testrec_dthdt\n",
    "        \n",
    "    def conversion_predictPC(self,yforecast=None,mshpe=[39,360,167]):\n",
    "        if self.optigoal=='surface':\n",
    "            t1,t2 = self.output_reshapeRECON(forecast_eig=yforecast)\n",
    "            return (t1.reshape(t1.shape[0],mshpe[0],mshpe[1],mshpe[2])[:,0,:,:]).reshape(t1.shape[0],mshpe[1]*mshpe[2]),(t2.reshape(t2.shape[0],mshpe[0],mshpe[1],mshpe[2])[:,0,:,:]).reshape(t2.shape[0],mshpe[1]*mshpe[2])\n",
    "        elif self.optigoal=='alluv':\n",
    "            t1,t2 = self.output_reshapeRECON(forecast_eig=yforecast)\n",
    "            return t1,t2\n",
    "        elif self.optigoal=='all': \n",
    "            t1,t2,t3,t4 = self.output_reshapeRECON(forecast_eig=yforecast)\n",
    "            return t1,t2,t3,t4\n",
    "    \n",
    "    def fit(self, X,y=None):\n",
    "        \"\"\"Learn features to select from X.\n",
    "        X (n_samples,n_features): Training vectors\n",
    "        Y (n_samples): Target values\n",
    "        \"\"\"\n",
    "        # Define basic settings\n",
    "        n_features = X.shape[1]\n",
    "        current_mask = np.zeros(shape=n_features,dtype=bool)\n",
    "        for index in self.startfeatures:\n",
    "            current_mask[index] = True\n",
    "        n_iteractions = self.n_features_to_select\n",
    "        \n",
    "        # Do forward selection\n",
    "        addinput,r2 = [],[]\n",
    "        clone_estimator = clone(self.estimator)\n",
    "        for _ in range(n_iteractions):\n",
    "            #new_feature_idx,r2t = self.get_best_new_feature_R2based(clone_estimator,X,y,current_mask)\n",
    "            if self.r2_based=='No':\n",
    "                new_feature_idx = self.get_best_new_feature(clone_estimator,X,y,current_mask)\n",
    "            else:\n",
    "                new_feature_idx,_ = self.get_best_new_feature_R2based(clone_estimator,X,y,current_mask,self.Xtrain,self.ytrain)\n",
    "            #r2.append(r2t)\n",
    "            current_mask[new_feature_idx] = True\n",
    "            addinput.append(current_mask)\n",
    "        \n",
    "        self.support_ = current_mask\n",
    "        self.new_feature = new_feature_idx\n",
    "        self.r2 = r2\n",
    "        return self\n",
    "    \n",
    "    def get_best_new_feature(self,estimator,X,y,current_mask):\n",
    "        candidate_feature_indices = np.flatnonzero(~current_mask)\n",
    "        scores={}\n",
    "        for feature_idx in candidate_feature_indices:\n",
    "            candidate_mask = current_mask.copy()\n",
    "            candidate_mask[feature_idx] = True\n",
    "            \n",
    "            # Add a new feature\n",
    "            X_new = X[:,candidate_mask]\n",
    "            # Improvement\n",
    "            scores[feature_idx] = cross_val_score(estimator,X_new,y,cv=self.cv,scoring=None,n_jobs=self.n_jobs).mean()\n",
    "        return max(scores,key=lambda feature_idx: scores[feature_idx])\n",
    "    \n",
    "    #--------------------------------------------------------------\n",
    "    # To do -> Add featureselector based on r2\n",
    "    # Candidate mask -> Xnew\n",
    "    # fit linear model with (Xnew,y)\n",
    "    # {output r2 term [time consideration => target: surface u/v]}...repeat for all u/v/w/theta members\n",
    "    # get component index that results in best r2 score\n",
    "    # --------[[Exit loops when r2 reaches 0.75?]]-----------------\n",
    "    # add to mask during fitting \n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "    def get_best_new_feature_R2based(self,estimator,X,y,current_mask,XtrainIN,ytrainIN):             \n",
    "        candidate_feature_indices = np.flatnonzero(~current_mask)\n",
    "        scores={}\n",
    "        for feature_idx in candidate_feature_indices:\n",
    "            candidate_mask = current_mask.copy()\n",
    "            candidate_mask[feature_idx] = True\n",
    "            # Add a new feature\n",
    "            X_new = X[:,candidate_mask]\n",
    "            Xtrain_new = [XtrainINobj[candidate_mask] for XtrainINobj in XtrainIN]\n",
    "            fittedmodel = LinearRegression().fit(Xtrain_new,ytrainIN)\n",
    "            # Forecast y_valid with trained model\n",
    "            y_forecast = fittedmodel.predict(X_new)\n",
    "            #################################################################################################################################################################################################################\n",
    "            # Forecast winds\n",
    "            #################################################################################################################################################################################################################\n",
    "            if self.optigoal=='surface':\n",
    "                print(\"Can't do surface wind R2 yet\")\n",
    "                break\n",
    "            else:\n",
    "                teMP1,teMP2,teMP3,teMP4 = self.conversion_predictPC(yforecast=y_forecast,mshpe=self.mshpe)                \n",
    "                scores[feature_idx] = r2_score(np.concatenate((self.realWRF[0],self.realWRF[1],self.realWRF[2],self.realWRF[3]),axis=0),np.concatenate((teMP1,teMP2,teMP3,teMP4),axis=0))\n",
    "        return max(scores,key=lambda feature_idx: scores[feature_idx]),max(scores.values())\n",
    "    \n",
    "    def _get_support_mask(self):\n",
    "        return self.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675ae194-1314-456d-ba85-b7e56d4b4e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dcec1f529c4bc0adffdc9b3c2399c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12a27f3c80b4070b26142fa50fedf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf32b3ffc3d4fa7b239fadb36eca672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/'\n",
    "suffix = '_smooth_preproc_dict1b_g'\n",
    "a = [read_and_proc.depickle(path+'TCGphy/2020_TC_CRF/dev/freddy0218/testML/output/haiyan/processed/uvwheat/'+'mem'+str(lime)+suffix)['u'].shape for lime in tqdm(range(1,21))]\n",
    "# divide experiments reference\n",
    "divider = np.asarray([aobj[0] for aobj in a]).cumsum()\n",
    "\n",
    "haiyan_u = np.concatenate([read_and_proc.depickle(path+'TCGphy/2020_TC_CRF/dev/freddy0218/testML/output/haiyan/processed/uvwheat/'+'mem'+str(lime)+suffix)['u'] for lime in tqdm(range(1,21))],axis=0)\n",
    "haiyan_v = np.concatenate([read_and_proc.depickle(path+'TCGphy/2020_TC_CRF/dev/freddy0218/testML/output/haiyan/processed/uvwheat/'+'mem'+str(lime)+suffix)['v'] for lime in tqdm(range(1,21))],axis=0)\n",
    "\n",
    "#folderpath='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/testML/output/haiyan/processed/'\n",
    "#PCAdict,dict2 = read_and_proc.depickle(folderpath+'pca/PCA'+'_'+'dict1_g'),read_and_proc.depickle(folderpath+'pca/PCA'+'_'+'dict2_g') #dict1: u,v,w,theta,hdia,rad; dict2:qv,ir\n",
    "#PCAdict['qv'] = (dict2['qv'])\n",
    "#PCAdict['ir'] = (dict2['ir'])\n",
    "\n",
    "dims = ['sample','flatarray']\n",
    "coords = dict(sample=np.linspace(0,haiyan_u.shape[0]-1,haiyan_u.shape[0]),flatarray=np.linspace(0,haiyan_u.shape[1]-1,haiyan_u.shape[1]))\n",
    "\n",
    "ds = xr.Dataset(coords=coords)\n",
    "haiyan_data=preproc_haiyan.build_a_xarray_dataset(ds=ds,varname=['u','v'],\\\n",
    "                                   varfile=[haiyan_u,haiyan_v],dims=dims,coords=coords)\n",
    "del haiyan_u,haiyan_v#,haiyan_w,haiyan_theta,dict2\n",
    "gc.collect()\n",
    "#,'qv'],\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89422c0-93c5-4f7f-8de3-f592b748c689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiyan_dataU,haiyan_dataV = haiyan_data['u'].data.reshape(1565,10,360,208),haiyan_data['v'].data.reshape(1565,10,360,208)\n",
    "del haiyan_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6963f425-cf75-4f9d-9b25-1bad9ed406f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.33333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "250/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16b69377-bc21-4f73-9fee-dcb3fe6851c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "du,dv = haiyan_dataU[5,8,...]-haiyan_dataU[5,2,...], haiyan_dataV[5,8,...]-haiyan_dataV[5,2,...]\n",
    "dus,dvs = np.nanmean(du[...,83:]),np.nanmean(dv[...,83:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d2f7de7-4e74-4aa7-a261-ff665bfe125f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.661654, -8.018406)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dus,dvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e204d84-0154-4c3d-98f8-66d3467cf643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "132.79154434609316 degree"
      ],
      "text/latex": [
       "$\\begin{pmatrix}132.79154434609316\\end{pmatrix}\\ \\mathrm{degree}$"
      ],
      "text/plain": [
       "array(132.79154435) <Unit('degree')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metpy.calc import wind_direction\n",
    "from metpy.units import units\n",
    "wind_direction(dus*units('m/s'), dvs*units('m/s'), convention='to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833b20f-e687-476d-953d-0e9d1734a092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
