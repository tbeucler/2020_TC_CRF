{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9000e705-b8da-4a82-ada4-1bca598ebc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1715589/1556194838.py:19: ProplotWarning: rc setting 'linewidth' was renamed to 'meta.width' in version 0.8.\n",
      "  plot.rc.update({'figure.facecolor':'w','axes.labelweight':'ultralight',\n"
     ]
    }
   ],
   "source": [
    "\"\"\"──────────────────────────────────────────────────────────────────────────┐\n",
    "│ Loading necessary libraries to build and train model                       │\n",
    "└──────────────────────────────────────────────────────────────────────────\"\"\"\n",
    "import os,sys,gc\n",
    "import numpy as np\n",
    "import pickle,glob\n",
    "import torch\n",
    "import proplot as plot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.insert(1, '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/scikit/')\n",
    "from tools import derive_var,read_and_proc\n",
    "from tools.mlr import mlr\n",
    "from tools.preprocess import do_eof,preproc_maria,preproc_haiyan\n",
    "sys.path.insert(2, '../')\n",
    "import read_stuff as read\n",
    "%matplotlib inline\n",
    "plot.rc.update({'figure.facecolor':'w','axes.labelweight':'ultralight',\n",
    "                'tick.labelweight':'ultralight','gridminor.linestyle':'--','title.weight':'normal','linewidth':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97e5094-49cb-402b-9eb2-25132a810c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/TCG_Rad_keras/maria\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d9699d-1cd3-4f00-a5e5-1e210cfe2093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78af161ac17e43488344efe361fd63ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/'\n",
    "suffix = '_smooth_preproc_dict1b_g'\n",
    "enter = '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/pca/output/uvwheat/preproc2/'\n",
    "\n",
    "maria_u = [read_and_proc.depickle(path+'TCGphy/2020_TC_CRF/dev/freddy0218/pca/output/uvwheat/preproc2/'+str(lime)+suffix)['u'] for lime in tqdm(['ctl','ncrf_36h','ncrf_60h','ncrf_96h','lwcrf'])]\n",
    "divider = np.asarray([maria_u[0][12:].shape[0],maria_u[1][25:].shape[0],maria_u[2][49:].shape[0],maria_u[3][85:].shape[0],maria_u[4][25:].shape[0]]).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c73418d-560f-4b08-8b0b-6f9ab9298043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/miniconda3/envs/fred_workenv/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator IncrementalPCA from version 1.1.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "folder = '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/testML/output/maria/processed/timeseries/'#intermediate/'\n",
    "Xtrain,Xvalid,Xtest,ytrain,yvalid,ytest = [],[],[],[],[],[]\n",
    "for expname in [2,3,4]:\n",
    "    obj = [read_and_proc.depickle(objs) for objs in sorted(glob.glob(folder+'inputoutput2/*val'+str(expname)))]\n",
    "    Xtest.append(obj[0])\n",
    "    Xtrain.append(obj[1])\n",
    "    Xvalid.append(obj[2])\n",
    "    ytest.append(obj[3])\n",
    "    ytrain.append(obj[4])\n",
    "    yvalid.append(obj[5])\n",
    "\n",
    "TYPE = '3D'\n",
    "if TYPE=='3D':\n",
    "    folderpath='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/testML/output/maria/processed/'\n",
    "    pcastore = read_and_proc.depickle(folderpath+'PCA/PCAdict3D')\n",
    "elif TYPE=='2D':\n",
    "    folderpath='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/testML/output/maria/processed/intermediate/'\n",
    "    pcastore = read_and_proc.depickle(folderpath+'PCA/PCAdict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed4273-5fa4-4966-87ba-cb14fc59b949",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1f6c29-45b7-4373-9a6b-c0ee6723a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimMLR_lwsw_3D_ts_dropout(torch.nn.Module):\n",
    "    def __init__(self,droprate):\n",
    "        #super(OptimMLR_all_2D, self).__init__()\n",
    "        super(OptimMLR_lwsw_3D_ts_dropout, self).__init__()\n",
    "        ############################################################\n",
    "        # Input channels\n",
    "        ############################################################\n",
    "        brchsize = [10,10]#[50,38,91,8,82,20,20]\n",
    "        self.dense1 = torch.nn.Linear(brchsize[0], 1)\n",
    "        self.dense2 = torch.nn.Linear(brchsize[1], 1)\n",
    "        self.dropout1 = torch.nn.Dropout(droprate)\n",
    "        self.dropout2 = torch.nn.Dropout(droprate)\n",
    "        self.dropout3 = torch.nn.Dropout(droprate)\n",
    "        ############################################################\n",
    "        # Final Dense Layer\n",
    "        ############################################################\n",
    "        self.denseout = torch.nn.Linear(2,1)#106)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        brchindex = list(np.asarray([0,54,26,50,75,12,10,10]).cumsum())\n",
    "        X_u, X_v, X_w, X_th = X[:,brchindex[0]:brchindex[1]],X[:,brchindex[1]:brchindex[2]],X[:,brchindex[2]:brchindex[3]],X[:,brchindex[3]:brchindex[4]]\n",
    "        X_hdia, X_lw, X_sw = X[:,brchindex[4]:brchindex[5]],X[:,brchindex[5]:brchindex[6]],X[:,brchindex[6]:brchindex[7]]\n",
    "        ############################################################\n",
    "        # Optimal PC layer\n",
    "        ############################################################\n",
    "        X_lwc = self.dropout1(X_lw)\n",
    "        bestlw = self.dense1(X_lwc)\n",
    "        X_swc = self.dropout2(X_sw)\n",
    "        bestsw = self.dense2(X_swc)\n",
    "        ############################################################\n",
    "        # Concat\n",
    "        ############################################################\n",
    "        bestPC = torch.cat((bestlw,bestsw),1)\n",
    "        ############################################################\n",
    "        # Prediction layer\n",
    "        ############################################################\n",
    "        bestPC = self.dropout3(bestPC)\n",
    "        outpred = self.denseout(bestPC)\n",
    "        return outpred\n",
    "    \n",
    "    def compute_l2_loss(self, w):\n",
    "        return torch.square(w).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3775c0-4206-4874-a038-17f96d2b8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimMLR_lwsw_3D_ts(torch.nn.Module):\n",
    "    def __init__(self,droprate):\n",
    "        #super(OptimMLR_all_2D, self).__init__()\n",
    "        super(OptimMLR_lwsw_3D_ts, self).__init__()\n",
    "        ############################################################\n",
    "        # Input channels\n",
    "        ############################################################\n",
    "        brchsize = [10,10]#[50,38,91,8,82,20,20]\n",
    "        self.dense1 = torch.nn.Linear(brchsize[0], 1)\n",
    "        self.dense2 = torch.nn.Linear(brchsize[1], 1)\n",
    "        self.dropout1 = torch.nn.Dropout(droprate)\n",
    "        self.dropout2 = torch.nn.Dropout(droprate)\n",
    "        self.dropout3 = torch.nn.Dropout(droprate)\n",
    "        ############################################################\n",
    "        # Final Dense Layer\n",
    "        ############################################################\n",
    "        self.denseout = torch.nn.Linear(2,1)#106)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        brchindex = list(np.asarray([0,54,26,50,75,12,10,10]).cumsum())\n",
    "        X_u, X_v, X_w, X_th = X[:,brchindex[0]:brchindex[1]],X[:,brchindex[1]:brchindex[2]],X[:,brchindex[2]:brchindex[3]],X[:,brchindex[3]:brchindex[4]]\n",
    "        X_hdia, X_lw, X_sw = X[:,brchindex[4]:brchindex[5]],X[:,brchindex[5]:brchindex[6]],X[:,brchindex[6]:brchindex[7]]\n",
    "        ############################################################\n",
    "        # Optimal PC layer\n",
    "        ############################################################\n",
    "        #X_lwc = self.dropout1(X_lw)\n",
    "        bestlw = self.dense1(X_lw)\n",
    "        #X_swc = self.dropout2(X_sw)\n",
    "        bestsw = self.dense2(X_sw)\n",
    "        ############################################################\n",
    "        # Concat\n",
    "        ############################################################\n",
    "        bestPC = torch.cat((bestlw,bestsw),1)\n",
    "        ############################################################\n",
    "        # Prediction layer\n",
    "        ############################################################\n",
    "        bestPC = self.dropout3(bestPC)\n",
    "        outpred = self.denseout(bestPC)\n",
    "        return outpred\n",
    "\n",
    "    def compute_l2_loss(self, w):\n",
    "        return torch.square(w).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b55242-3057-4075-9f09-d8f2147aa971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import ts_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52188696-e594-4503-a29f-04e1af12c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(2, '../')\n",
    "def get_bestparams(splitnum=None,n_trials=20,train='Yes'):\n",
    "    X_totrain,y_totrain = read.train_optimizedMLR(folderpath,folderpath2).delete_padding(Xtrain[splitnum],ytrain[splitnum])#yall_orig[splitnum][23][0])\n",
    "    X_tovalid,y_tovalid = read.train_optimizedMLR(folderpath,folderpath2).delete_padding(Xvalid[splitnum],yvalid[splitnum])#yall_orig[splitnum][23][1])   \n",
    "    calc_device = 'cpu'\n",
    "    ###################################################################################\n",
    "    # Convert numpy arrays into tensors\n",
    "    ###################################################################################\n",
    "    train_Xtensor = torch.FloatTensor(X_totrain).to(calc_device)\n",
    "    train_ytensor = torch.FloatTensor(y_totrain).to(calc_device)\n",
    "    val_Xtensor = torch.FloatTensor(X_tovalid).to(calc_device)\n",
    "    val_ytensor = torch.FloatTensor(y_tovalid).to(calc_device)\n",
    "    train_data = torch.utils.data.TensorDataset(train_Xtensor, train_ytensor)\n",
    "    val_data = torch.utils.data.TensorDataset(val_Xtensor, val_ytensor)\n",
    "    batch_size = 5\n",
    "    num_workers = 2\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_data,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    def objective(trial):\n",
    "        models,losses = [],[]\n",
    "        droprate = trial.suggest_float(\"droprate\",0.05,0.45)\n",
    "        #model = OptimMLR_lwsw_3D_ts_dropout(droprate)\n",
    "        model = OptimMLR_lwsw_3D_ts(droprate)\n",
    "        lr = trial.suggest_float(\"lr\",1e-5,1e-3)#,log=True)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "        criterion = torch.nn.L1Loss()\n",
    "        n_epochs = 1500\n",
    "        scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-5,cycle_momentum=False)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=1e-12)\n",
    "        l2_lambda = trial.suggest_float(\"l2_lambda\",0.01,0.02)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            loss = 0\n",
    "            for features, labels in train_loader:\n",
    "                optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "                output = model(features)\n",
    "                batch_loss = criterion(output, labels.unsqueeze(1))\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            loss += batch_loss.item()\n",
    "            loss = loss/len(train_loader)\n",
    "            train_losses.append(loss)\n",
    "            val_loss = ts_models.eval_model(model,\n",
    "                                            val_loader,\n",
    "                                            criterion,\n",
    "                                            l2_lambda)\n",
    "            val_losses.append(val_loss)\n",
    "            if epoch%100 == 0:\n",
    "                print('Epoch: {}/{}.............'.format(epoch, n_epochs))\n",
    "                print(\"Loss: {:.4f}\".format(loss))\n",
    "        return loss\n",
    "    if train=='Yes':\n",
    "        study = optuna.create_study(directions=[\"minimize\"])\n",
    "        study.optimize(objective, n_trials=n_trials)#, timeout=300)\n",
    "        return study, train_loader, val_loader\n",
    "    else:\n",
    "        return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a46e3864-7d69-4c7f-b35b-cc1c0a6f5074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folderpath='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/TCG_Rad_keras/store/'\n",
    "folderpath2='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/TCGphy/2020_TC_CRF/dev/freddy0218/testML/output/haiyan/processed/new3D/'\n",
    "#bestparams,train_loader,val_loader = get_bestparams(splitnum=2,n_trials=20)\n",
    "#read_and_proc.save_to_pickle('./models/1d/nomc2/4/bestparams.pkt',bestparams,'PICKLE')\n",
    "bestparams = read_and_proc.depickle('./models/1d/mcdrop2/4/bestparams.pkt')\n",
    "train_loader,val_loader = get_bestparams(splitnum=2,n_trials=20,train='No')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8143ceb-0668-4dd8-9b3f-998a06041130",
   "metadata": {},
   "source": [
    "#### 0 best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd0c8a42-d9b9-4781-9dd5-8ee3bdce070b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'droprate': 0.34831132482125615,\n",
       " 'lr': 0.0007215452041872332,\n",
       " 'l2_lambda': 0.017553586437368145}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestparams.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d382ab-6e0e-4c8f-ae29-4f992112edc9",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "564a706a-6ff0-462b-82c4-58ccb635d87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bf60d2f9664e92bf39cb651681e4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.32199541411616583, 0.21542634842917324)\n",
      "(0.10165733098983765, 0.09722645892761647)\n",
      "(0.02428903392600742, 0.05143971294164658)\n",
      "(0.008395023538138379, 0.027051787870004774)\n",
      "(0.0037905643528740093, 0.016580600757151842)\n",
      "(0.00203462476751652, 0.010793128306977451)\n",
      "(0.0010104650996667756, 0.00801533421035856)\n",
      "(0.0007366331986469794, 0.0067322135902941225)\n",
      "(0.0003509114759584587, 0.005304471380077303)\n",
      "(0.00021590680241636372, 0.004275644407607615)\n",
      "(9.456359330008787e-05, 0.0035904138116165996)\n",
      "(1.774300739818748e-05, 0.0030034224735572936)\n",
      "(1.7040907229759483e-07, 0.0026080514187924566)\n",
      "(6.777369941772401e-09, 0.002575498353689909)\n",
      "(5.595357714408253e-09, 0.002556220896076411)\n",
      "(4.7304245230513206e-09, 0.0025492351618595422)\n",
      "(4.308894545303577e-09, 0.002538931043818593)\n",
      "(4.319489157769948e-09, 0.002526903385296464)\n",
      "(3.327782683884814e-09, 0.0025135244242846964)\n",
      "(3.701734616120354e-09, 0.00249289731727913)\n",
      "(2.2383785655176835e-09, 0.002475978271104395)\n",
      "(3.3668009075116245e-09, 0.002459353650920093)\n",
      "(4.081228953905553e-09, 0.0024352514068596066)\n",
      "(3.2048277302167767e-09, 0.0024136357707902787)\n",
      "(2.8133240118834797e-09, 0.0023952031740918757)\n",
      "(4.131834014136183e-09, 0.00237131139729172)\n",
      "(2.9455135519346576e-09, 0.002346762747038156)\n",
      "(2.229634572298805e-09, 0.002326562604866922)\n",
      "(2.6590703091116208e-09, 0.0023031190037727358)\n",
      "(3.0820228023738364e-09, 0.002276059438008815)\n",
      "(3.2045257139133965e-09, 0.0022531012538820503)\n",
      "(2.7948834771151054e-09, 0.0022312413319014015)\n",
      "(2.4336824881732166e-09, 0.002203227370046079)\n",
      "(3.1572360116141366e-09, 0.0021812929189763963)\n",
      "(3.689779196196104e-09, 0.0021599280647933484)\n",
      "(3.0257827392622294e-09, 0.00213263554032892)\n",
      "(3.4784240289268105e-09, 0.0021069284528493883)\n",
      "(2.589965222342678e-09, 0.002083505201153457)\n",
      "(3.188331308563845e-09, 0.0020605240482836963)\n",
      "(2.6629127227148245e-09, 0.002033734554424882)\n",
      "(2.8424692505049894e-09, 0.0020122784888371827)\n",
      "(2.6643953657951025e-09, 0.0019889084855094553)\n",
      "(2.6998048683032653e-09, 0.0019623459316790103)\n",
      "(2.4847149934939024e-09, 0.0019402049423661084)\n",
      "(3.122964236644417e-09, 0.0019188426027540117)\n",
      "(3.627042066311027e-09, 0.001895035564666614)\n",
      "(3.0931735670289033e-09, 0.0018718819075729698)\n",
      "(2.6691307806646736e-09, 0.0018498739053029567)\n",
      "(2.935964058360284e-09, 0.0018280774005688728)\n",
      "(2.1916748558049493e-09, 0.0018031425192020834)\n",
      "(2.6513434970237334e-09, 0.0017835352220572532)\n",
      "(3.3299028476988968e-09, 0.0017645737680140883)\n",
      "(3.2461957815623573e-09, 0.001742036937503144)\n",
      "(2.508021762019767e-09, 0.0017202357295900584)\n",
      "(2.8291916044768813e-09, 0.0017020463186781854)\n",
      "(2.451793064027864e-09, 0.001680996094364673)\n",
      "(2.98689323464057e-09, 0.0016567796585150063)\n",
      "(2.752001790908136e-09, 0.0016382001049350947)\n",
      "(2.9056509654154265e-09, 0.001617112068925053)\n",
      "(2.9556269635027717e-09, 0.0015953355119563638)\n",
      "(3.165605861250738e-09, 0.0015783210285007954)\n",
      "(3.040600809328664e-09, 0.0015606115630362183)\n",
      "(3.129818765583815e-09, 0.0015386862971354276)\n",
      "(2.3796046351821543e-09, 0.001519935007672757)\n",
      "(2.145329175039613e-09, 0.0015017930534668266)\n",
      "(2.9810630998123766e-09, 0.0014808248612098395)\n",
      "(2.305363015385854e-09, 0.0014612308179493994)\n",
      "(2.5622835592532434e-09, 0.0014439297723583878)\n",
      "(2.7469438911020827e-09, 0.0014254911278840155)\n",
      "(2.936259527817266e-09, 0.0014075157407205552)\n",
      "(2.2415945043965176e-09, 0.0013915784598793834)\n",
      "(2.966862666211903e-09, 0.0013747855904512108)\n",
      "(2.312271801202415e-09, 0.0013572867086622865)\n",
      "(2.5804873821720013e-09, 0.001341110438806936)\n",
      "(0.2779205427505076, 0.17779940608888864)\n",
      "(0.07026123662944883, 0.06310762534849346)\n",
      "(0.01820167169948532, 0.02104942554142326)\n",
      "(0.0041532241024965924, 0.008994312107097358)\n",
      "(0.0008926731207710956, 0.003691757074557245)\n",
      "(0.00013606833933656824, 0.001347299717599526)\n",
      "(1.1378828531860563e-05, 0.00042072812939295543)\n",
      "(3.9802639632698217e-07, 0.00013024626532569527)\n",
      "(3.2502168961274173e-09, 8.725037623662502e-05)\n",
      "(0.3491027473726056, 0.3548568218946457)\n",
      "(0.17030081152915955, 0.18039751425385475)\n",
      "(0.060950867239047184, 0.0801945984363556)\n",
      "(0.012208880301014606, 0.02597088008187711)\n",
      "(0.001808775689245191, 0.010982545278966426)\n",
      "(0.0003331153709702696, 0.006269746855832636)\n",
      "(1.3398086076547728e-06, 0.004918163223192096)\n",
      "(1.350887269723312e-08, 0.004898575809784233)\n",
      "(1.1468724125057223e-08, 0.004861083091236651)\n",
      "(0.1932666485451839, 0.26351453848183154)\n",
      "(0.0722370917739516, 0.11166545855812729)\n",
      "(0.016166606677209282, 0.027814362314529717)\n",
      "(0.004356015818220013, 0.011445950251072645)\n",
      "(0.0013303811124801127, 0.0066328805172815915)\n",
      "(0.0003421651576900331, 0.00497764132451266)\n",
      "(7.555230789338648e-05, 0.003986328339669854)\n",
      "(5.110581256931565e-06, 0.0034181359806098044)\n",
      "(1.203394249905575e-08, 0.003292859240900725)\n",
      "(6.143998545406835e-09, 0.0032577934907749295)\n",
      "(2.466270228129225e-09, 0.0032428463455289602)\n",
      "(4.349764314520216e-09, 0.0032245828886516394)\n",
      "(3.8850810814977654e-09, 0.003199490311089903)\n",
      "(2.7100536723183174e-09, 0.003176133683882654)\n",
      "(2.880433278890598e-09, 0.003152729757130146)\n",
      "(2.8485715027312423e-09, 0.003127391031011939)\n",
      "(3.3735123605589793e-09, 0.0031042797956615685)\n",
      "(3.2732799491730358e-09, 0.003084035962820053)\n",
      "(3.773532682665498e-09, 0.0030609475448727607)\n",
      "(2.3743685268391586e-09, 0.003034495620522648)\n",
      "(3.1616810280965524e-09, 0.0030147926765494047)\n",
      "(3.6790727623505566e-09, 0.0029944672947749495)\n",
      "(2.6568670836623165e-09, 0.0029674060177057983)\n",
      "(3.478453796466254e-09, 0.002945189387537539)\n",
      "(3.5919837147293824e-09, 0.0029246607329696415)\n",
      "(3.3378762292025532e-09, 0.0029029691009782254)\n",
      "(2.495444795878245e-09, 0.002878986834548414)\n",
      "(2.4504099604845523e-09, 0.002859222539700568)\n",
      "(2.694585794077442e-09, 0.0028365796082653106)\n",
      "(2.31143353794271e-09, 0.0028127684374339877)\n",
      "(2.7135623360061904e-09, 0.0027932174503803252)\n",
      "(2.7266079059966183e-09, 0.0027724931831471624)\n",
      "(3.0251380384291064e-09, 0.002749507850967348)\n",
      "(2.743888665206574e-09, 0.0027286944445222617)\n",
      "(3.087227922484019e-09, 0.002708613104186952)\n",
      "(2.879016568312833e-09, 0.0026849025627598165)\n",
      "(2.560246925134316e-09, 0.002663384354673326)\n",
      "(2.5295406927543103e-09, 0.002644860080908984)\n",
      "(2.7682959419113432e-09, 0.002623365295585245)\n",
      "(2.7089525018693006e-09, 0.002600608009379357)\n",
      "(3.0332719262474413e-09, 0.0025827268720604478)\n",
      "(3.460519639150475e-09, 0.0025617895182222126)\n",
      "(3.350903471366351e-09, 0.0025374959339387717)\n",
      "(2.7002587303143703e-09, 0.002517289377283305)\n",
      "(2.5762043041761954e-09, 0.0024986880132928492)\n",
      "(2.9084411366029554e-09, 0.002474657364655286)\n",
      "(2.6392300258127788e-09, 0.0024534811382181942)\n",
      "(2.585563939717549e-09, 0.002435104292817414)\n",
      "(3.6605122090037734e-09, 0.002416213182732463)\n",
      "(2.960844867263355e-09, 0.002392967406194657)\n",
      "(2.9903898580859027e-09, 0.0023741194745525718)\n",
      "(2.5582665045719255e-09, 0.0023550315061584117)\n",
      "(3.173352518890595e-09, 0.0023336559301242233)\n",
      "(2.4790001041524734e-09, 0.0023173810448497536)\n",
      "(2.4776583026404012e-09, 0.002297645388171077)\n",
      "(3.0366739325125218e-09, 0.002275554579682648)\n",
      "(2.4563715706357988e-09, 0.0022559280274435877)\n",
      "(2.8459292364328074e-09, 0.002238022885285318)\n",
      "(4.2435670974646815e-09, 0.0022183363791555165)\n",
      "(2.756685745836601e-09, 0.0021981589845381675)\n",
      "(2.3000982129029912e-09, 0.002180435147602111)\n",
      "(3.388541466044352e-09, 0.0021625792840495707)\n",
      "(2.5457732677764615e-09, 0.0021407729596830904)\n",
      "(2.7119804776245334e-09, 0.0021232101251371207)\n",
      "(2.6338154479358085e-09, 0.0021071497933007775)\n",
      "(3.865528230839743e-09, 0.0020875641610473396)\n",
      "(2.7786514170692737e-09, 0.0020678201224654915)\n",
      "(2.403345031825649e-09, 0.002052016416564584)\n",
      "(2.4982015474603074e-09, 0.0020346354926005007)\n",
      "(2.9405350184479925e-09, 0.002014116698410362)\n",
      "(2.094642125469423e-09, 0.0019981954246759415)\n",
      "(2.6163163109321004e-09, 0.0019811393111012878)\n",
      "(2.8250416176201954e-09, 0.00196013106033206)\n",
      "(2.2536214122752126e-09, 0.0019431586086284369)\n",
      "(0.362577599896626, 0.16465473715215923)\n",
      "(0.14194888925306837, 0.062454763893038036)\n",
      "(0.04731721485785039, 0.02808292310219258)\n",
      "(0.010221326535842805, 0.01379652989562601)\n",
      "(0.0026499281052152087, 0.008401549828704447)\n",
      "(0.00032722988767504415, 0.003696267190389335)\n",
      "(3.9498147853836684e-05, 0.0015701335621997714)\n",
      "(1.725692344295931e-06, 0.0010834969754796476)\n",
      "(3.025993173836036e-09, 0.001025660359300673)\n",
      "(2.871035270635147e-09, 0.0009738616878166795)\n",
      "(3.2277102004409715e-09, 0.0009301378391683102)\n",
      "(3.3072883510126324e-09, 0.00089379258279223)\n",
      "(3.4878075200700017e-09, 0.0008581117115681991)\n",
      "(3.013533297271185e-09, 0.0008312979451147839)\n",
      "(2.8274651575243104e-09, 0.000808793626492843)\n",
      "(3.540611479507289e-09, 0.0007867441163398325)\n",
      "(2.5307734525450228e-09, 0.0007678914698772132)\n",
      "(2.8459080023135463e-09, 0.0007529621478170156)\n",
      "(2.91889559397851e-09, 0.0007399400434223935)\n",
      "(2.806576593287404e-09, 0.0007269272289704531)\n",
      "(3.1659650018404802e-09, 0.0007180363842053339)\n",
      "(2.6461119189110953e-09, 0.0007098816247889772)\n",
      "(2.468788525253088e-09, 0.000701088723144494)\n",
      "(2.6353725779920175e-09, 0.0006939554121345281)\n",
      "(3.1679822010637956e-09, 0.0006876319472212345)\n",
      "(3.0923173403232048e-09, 0.0006803020543884486)\n",
      "(2.8832932146636496e-09, 0.0006736233422998339)\n",
      "(2.6320378570772085e-09, 0.0006677356926957145)\n",
      "(2.9242346845749123e-09, 0.0006614233105210587)\n",
      "(2.7533351675779446e-09, 0.0006549748504767194)\n",
      "(2.9137628048983818e-09, 0.0006497344031231478)\n",
      "(2.9774577550964213e-09, 0.0006444593687774614)\n",
      "(2.9714022930933796e-09, 0.0006381894869264215)\n",
      "(2.250594726050331e-09, 0.0006324055721051991)\n",
      "(2.858486987515492e-09, 0.0006266828568186611)\n",
      "(2.5383381157716533e-09, 0.000620769985835068)\n",
      "(2.7436155126122808e-09, 0.0006145021587144583)\n",
      "(2.8814442076050754e-09, 0.0006086755922297016)\n",
      "(2.355774553492653e-09, 0.0006031059572705999)\n",
      "(2.8614860228789755e-09, 0.000596492679324001)\n",
      "(2.4388543771319826e-09, 0.00059169226733502)\n",
      "(2.9022404694136546e-09, 0.0005862383462954312)\n",
      "(2.522175387418986e-09, 0.0005807306413771584)\n",
      "(2.6665768210955916e-09, 0.0005752032826421783)\n",
      "(2.607735250432937e-09, 0.0005697831278666854)\n",
      "(4.02335681816034e-09, 0.000564193434547633)\n",
      "(2.8189062134089974e-09, 0.0005576949886744841)\n",
      "(2.551338159994582e-09, 0.0005525902932276949)\n",
      "(2.5124055749347163e-09, 0.0005468514253152534)\n",
      "(3.0492787143141724e-09, 0.0005404468247434124)\n",
      "(2.5027091882487166e-09, 0.0005353344953618943)\n",
      "(2.4484376820833498e-09, 0.0005300773278577253)\n",
      "(2.9303501337100083e-09, 0.0005236067489022389)\n",
      "(2.882430121764731e-09, 0.0005181048269150779)\n",
      "(2.5554018178643796e-09, 0.0005125727853737772)\n",
      "(3.368910322584795e-09, 0.0005060585855972022)\n",
      "(2.6013475530858613e-09, 0.0005003172409487888)\n",
      "(2.2140824096792107e-09, 0.0004953805269906298)\n",
      "(3.3612832012702206e-09, 0.0004898884566500783)\n",
      "(2.7555644426600283e-09, 0.0004832887585507706)\n",
      "(2.412216419667157e-09, 0.0004782509102369659)\n",
      "(2.684631039569356e-09, 0.00047327555512310937)\n",
      "(3.4530370762857073e-09, 0.00046709236048627647)\n",
      "(2.5633696380811255e-09, 0.0004620726977009326)\n",
      "(2.6694201545202014e-09, 0.0004567044088616967)\n",
      "(2.584142632201424e-09, 0.0004515098160482012)\n",
      "(2.485484357312137e-09, 0.0004455180314835161)\n",
      "(2.9969175139875097e-09, 0.0004406822015880607)\n",
      "(3.208909732629631e-09, 0.00043543231004150584)\n",
      "(2.613973218119524e-09, 0.00042953629017574715)\n",
      "(2.8682109014244173e-09, 0.0004247686796588823)\n",
      "(2.677931144511415e-09, 0.0004195198052912019)\n",
      "(3.3330307428166865e-09, 0.00041454843449173495)\n",
      "(2.18864507956445e-09, 0.00040944727370515464)\n",
      "(0.0934744037010453, 0.10244270022958517)\n",
      "(0.01415187353532846, 0.022777985967695712)\n",
      "(0.001515873414973612, 0.006309501361101866)\n",
      "(0.00014866134103964544, 0.004358698334544897)\n",
      "(9.953466304905718e-07, 0.0037369364872574806)\n",
      "(1.3261480267458901e-08, 0.0037169559625908734)\n",
      "(1.0170621965833636e-08, 0.0036846402217634022)\n",
      "(0.39278811250220647, 0.8856092754751443)\n",
      "(0.15807849448174238, 0.4993437334895134)\n",
      "(0.04359056119045073, 0.20227758046239613)\n",
      "(0.009913896930150011, 0.06207370841875672)\n",
      "(0.0029700989332261747, 0.023817658983170988)\n",
      "(0.0008698378448819064, 0.007800468138884753)\n",
      "(0.00024149198192059305, 0.0032246474525891244)\n",
      "(3.607815295936234e-05, 0.002021738886833191)\n",
      "(1.6240784788124074e-06, 0.0015534704667516052)\n",
      "(8.904376632499413e-09, 0.0014129997580312192)\n",
      "(5.978498027444959e-09, 0.001388763781869784)\n",
      "(3.803328032564951e-09, 0.0013880125887226313)\n"
     ]
    }
   ],
   "source": [
    "times = ['exp1a','exp1b','exp1c','exp1d','exp1e','exp1f','exp1g']\n",
    "#times = ['exp2a','exp2b','exp2c']#,'exp1d','exp1e']\n",
    "exp = 4\n",
    "for i in tqdm(range(len(times))):\n",
    "    models,losses = [],[]\n",
    "    #model = OptimMLR_lwsw_3D_ts(bestparams.best_params['droprate'])\n",
    "    model = OptimMLR_lwsw_3D_ts_dropout(bestparams.best_params['droprate'])\n",
    "    optimizers = [torch.optim.Adam(model.parameters(), lr=bestparams.best_params['lr'])]#, optim.AdaBound(model.parameters(),lr=1e-7)] 1e-6\n",
    "    loss = torch.nn.MSELoss()\n",
    "    for optimizer in optimizers:\n",
    "        scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-9, max_lr=2e-5,cycle_momentum=False)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=1e-18)\n",
    "        num_epochs = 1000*22#26\n",
    "        early_stopper = ts_models.EarlyStopping(patience=260, verbose=False, delta=1e-8, path='checkpoint.pt', trace_func=print)#EarlyStopper(patience=8, min_delta=1e-3)\n",
    "                #variance_store = [varu,varv,varw,varth]\n",
    "                #variance_store = [varu,varv,varth]\n",
    "        model,loss = ts_models.train_model(model=model,optimizer=optimizer,scheduler=[scheduler,scheduler2],numepochs=num_epochs,early_stopper=early_stopper,variance_store=None,\\\n",
    "                                 lossfunc=loss,train_loader=train_loader,val_loader=val_loader,test_loader=None,l2_lambda=bestparams.best_params['l2_lambda'])\n",
    "        models.append(model)\n",
    "        losses.append(loss)\n",
    "    torch.save(models, './models/1d/mcdrop2/'+str(exp)+'/models_LWSW1d_1115_'+str(times[i])+'.pt')\n",
    "    read_and_proc.save_to_pickle('./models/1d/mcdrop2/'+str(exp)+'/losses_LWSW1d_1115_'+str(times[i])+'.pkt',losses,'PICKLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e207ad5-dd08-42c0-a642-88fc25087db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2847f88-9baf-462b-a404-d7446631a862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
